# Here's where you define experiment-specific hyperparameters.
# You can also create lists and group parameters together into nested sub-parts.
# In Python, this is all read as a dict.

# selecting dataset
test_dataset: test_bermuda
num_classes: 7 # all are 2, excpet bermuda = 7. 
train_percent: 0.2 # change for dataset

#ReefCLR or Imagenet wights? If starting_weights: None, it defaults to imagenet. If path to a checkpoint then ReefCLR
starting_weights: None #/home/ben/reef-audio-representation-learning/code/simclr-pytorch-reefs/logs/exman-train.py/runs/baseline/checkpoint-5100.pth.tar

# dataset parameters
data_root: /mnt/ssd-cluster/ben/data/full_dataset/ # provs redundant, coukd remove
data_path: /mnt/ssd-cluster/ben/data/full_dataset/
json_path: /home/ben/reef-audio-representation-learning/data/dataset.json

# Hyper parameters
num_epochs: 2
batch_size: 128
learning_rate: 0.001
weight_decay: 0.001

# Not to change
finetune: True # this will only train the head if true.
image_size: [224, 224]


# environment/computational parameters
seed: 0       # random number generator seed (long integer value)
device: cuda
num_workers: 4


# think below is all junk
train_label_file: [/root/10_percent_train_with_unknown.csv]
#train_label_file: [/root/10_percent_train_with_unknown.csv, /root/10p_predictions_on_unlabeled_thresh_0.1_simclr.csv]
val_label_file: /root/5_percent_val_with_unknown.csv
test_label_file: /root/10_percent_test_with_unknown.csv
unlabeled_file: /root/75_percent_unlabeled_with_unknown.csv
#inference_weights: /root/ct_classifier/model_states_paws/10p_paws_200.pt
#inference_weights: /root/ct_classifier/model_states_simclr/200.pt
inference_weights: /root/ct_classifier/model_states/resnet50_10p_200epochs.pt

# Put None if using imagenet e.g starting_weights: None

